{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z63y0LhjQTat"
      },
      "source": [
        "# **Key Inputs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQzih150Uh_J"
      },
      "outputs": [],
      "source": [
        "##NOTE - INPUT IS REQUIRED IN THIS SECTION\n",
        "#=============================================================================\n",
        "#Input data csv must be saved to your Google Drive, and the file path\n",
        "#and name below updated as needed, in order for this program to run.\n",
        "\n",
        "##INPUT DATA\n",
        "#============\n",
        "#Root directory (leave blank for local PC run):\n",
        "file_path = ''#'/content/drive/My Drive/Colab Notebooks/GNN_Geomodeling/'\n",
        "#Input drillhole training data (each is optional, but must at least provide an empty file with headers):\n",
        "input_rock_unit_filename = 'Input_Data/MSOP_drillhole_data.csv'#'Input_Data/Folded_Rock_Unit.csv'#\n",
        "input_geologic_contact_filename = 'Input_Data/Folded_Geologic_Contacts.csv'\n",
        "input_orientations_filename = 'Input_Data/Folded_Orientations.csv'\n",
        "#'Input_Data/MSOP_drillhole_data.csv'\n",
        "#'Input_Data/GeoLogic_int_drillhole_data.csv'\n",
        "\n",
        "#Input data attributes (Column names)\n",
        "#X,Y,Z must have the same name in all 3 input files\n",
        "input_name_x = \"X\"\n",
        "input_name_y = \"Y\"\n",
        "input_name_z = \"Z\"\n",
        "#rock unit:\n",
        "input_name_rock_unit = \"RockUnit\"\n",
        "#geologic contacts:\n",
        "input_name_geologic_contact = \"FieldValue\"\n",
        "#orientations:\n",
        "input_name_x_vec = \"XVec\"\n",
        "input_name_y_vec = \"YVec\"\n",
        "input_name_z_vec = \"ZVec\"\n",
        "\n",
        "##MESH SETTINGS\n",
        "#===============\n",
        "#Mesh extents and size in X,Y,Z (if less than the above dataset extents, data will be filtered)\n",
        "min_extents = [6200,7000,1400]#[1000,2300,1690]##[2400,5100,2100]\n",
        "max_extents = [6800,7400,1700]#[1100,2480,1770]##[3200,5600,2700]\n",
        "max_volume = 1000#50# #max volume of each tetrahedra in the tetrahedral mesh\n",
        "\n",
        "#Set x-slice for mesh/graph visualization on 3D plots\n",
        "min_viewing_x = 6725#1040#2825#\n",
        "max_viewing_x = 6745#1050#2845#\n",
        "\n",
        "##NEURAL NETWORK MODEL SETTINGS\n",
        "#==============================\n",
        "mUseGPUIfAvailable = True\n",
        "# Proportions of data for training vs validation dataset, should sum to 1:\n",
        "mTrainingPercent = 0.85\n",
        "mValidationPercent = 0.15\n",
        "\n",
        "##OUTPUT SETTINGS\n",
        "#=================\n",
        "save_model_input_data = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffjCzvDtvZ_F"
      },
      "source": [
        "# **Configure & install dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErL-uWxkX8hB",
        "outputId": "24e3edee-5816-411c-d2bb-fb16ba06af9d"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvCVg8i9qlOv",
        "outputId": "4ca1d55c-93e1-4d6f-c38d-cfd9468b6d3b"
      },
      "outputs": [],
      "source": [
        "# We assume that PyTorch is already installed\n",
        "import torch\n",
        "#torchversion = torch.__version__\n",
        "\n",
        "# Install PyTorch Scatter, PyTorch Sparse, and PyTorch Geometric\n",
        "#!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-{torchversion}.html\n",
        "#!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-{torchversion}.html\n",
        "#!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "#!pip install -q meshpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(torch.cuda.is_available())\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and mUseGPUIfAvailable) else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szo7Eqvet81l"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from mpl_toolkits.mplot3d.art3d import Line3DCollection\n",
        "from meshpy.tet import MeshInfo, build\n",
        "from meshpy.geometry import GeometryBuilder, Marker, make_box\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "import math\n",
        "import sys\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch.nn import Linear, Dropout\n",
        "from torch_geometric.nn import SAGEConv\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from scipy.spatial import cKDTree\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do7xRZyRvf-f"
      },
      "source": [
        "# **Mesh generation**\n",
        "___________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUgbeaR5EiGS"
      },
      "source": [
        "**Meshing Helper Functions:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6n0bFOx1vDrn"
      },
      "outputs": [],
      "source": [
        "#Function to generate edge list from tetrahedra\n",
        "def generate_edges_from_ele(element_array):\n",
        "    edges = set()\n",
        "    for element in element_array:\n",
        "        element = sorted(element)\n",
        "        for i in range(len(element)):\n",
        "            for j in range(i+1,len(element)):\n",
        "                edge = tuple([element[i],element[j]])\n",
        "                edges.add(edge)\n",
        "    return np.array(list(edges))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjxAzzRPAqjZ"
      },
      "outputs": [],
      "source": [
        "def edge_length_stats(edges,nodes):\n",
        "  edge_lengths = []\n",
        "  for edge in edges:\n",
        "    # Calculate the Euclidean distance between the nodes\n",
        "    length = np.linalg.norm(nodes[edge[0]] - nodes[edge[1]])\n",
        "    # Append the edge length to the list\n",
        "    edge_lengths.append(length)\n",
        "\n",
        "  # Calculate min, max, and mean edge lengths\n",
        "  min_length = np.min(edge_lengths)\n",
        "  max_length = np.max(edge_lengths)\n",
        "  mean_length = np.mean(edge_lengths)\n",
        "\n",
        "  #print\n",
        "  print(\"min edge length: %.3f\" % min_length)\n",
        "  print(\"max edge length: %.3f\" % max_length)\n",
        "  print(\"mean edge length: %.3f\" % mean_length)\n",
        "  return edge_lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfZ_udQZDrG8"
      },
      "outputs": [],
      "source": [
        "#plot histogram\n",
        "def histo(data):\n",
        "  # Plotting a histogram\n",
        "  plt.hist(data, bins=30, edgecolor='black')  # Adjust the number of bins as needed\n",
        "  plt.title('Histogram')\n",
        "  plt.xlabel('Edge Length')\n",
        "  plt.ylabel('Frequency')\n",
        "  plt.grid(True)\n",
        "  plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwjmbFJhwQRK"
      },
      "outputs": [],
      "source": [
        "def visualize(mesh_points,mesh_edges):\n",
        "  # Access the mesh points and elements\n",
        "  mesh_points = np.array(mesh.points)\n",
        "\n",
        "  # Visualize the tetrahedral mesh using matplotlib\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "  # Plot the mesh edges\n",
        "  edge_points = [(mesh_points[edge[0]], mesh_points[edge[1]]) for edge in mesh_edges]\n",
        "  edge_collection = Line3DCollection(edge_points, color='g')  # You can adjust the color here\n",
        "  ax.add_collection3d(edge_collection)\n",
        "\n",
        "  # Plot the mesh points\n",
        "  ax.scatter(mesh_points[:, 0], mesh_points[:, 1], mesh_points[:, 2], color='r', marker='o')\n",
        "\n",
        "  # Set the extents of the plot (change the values accordingly)\n",
        "  ax.set_xlim(min_extents[0], max_extents[0])\n",
        "  ax.set_ylim(min_extents[1], max_extents[1])\n",
        "  ax.set_zlim(min_extents[2], max_extents[2])\n",
        "\n",
        "  ax.set_xlabel('X')\n",
        "  ax.set_ylabel('Y')\n",
        "  ax.set_zlabel('Z')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUvqvmj7EkeT"
      },
      "source": [
        "**Meshing main:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rNTt4dzu2J2"
      },
      "outputs": [],
      "source": [
        "points, facets, _, facet_markers = make_box(min_extents, max_extents)\n",
        "\n",
        "mesh_info = MeshInfo()\n",
        "mesh_info.set_points(points)\n",
        "mesh_info.set_facets(facets)\n",
        "\n",
        "mesh = build(mesh_info, max_volume=max_volume,volume_constraints=True, attributes=False, insert_points=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "Ygaaz1Liu71E",
        "outputId": "546b9aa4-f6c3-4121-b72d-31b2164c3ec7"
      },
      "outputs": [],
      "source": [
        "#retrieve true edge list and run stats\n",
        "mesh_faces = np.array(mesh.faces)\n",
        "mesh_elements = np.array(mesh.elements)\n",
        "mesh_edges = generate_edges_from_ele(mesh_elements)\n",
        "mesh_points = np.array(mesh.points)\n",
        "edge_lengths = edge_length_stats(mesh_edges,mesh_points)\n",
        "histo(edge_lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pgqllc1WvQ-j",
        "outputId": "fc9f3fb0-413f-43cc-e523-4bb9a14831cb"
      },
      "outputs": [],
      "source": [
        "#print initial mesh\n",
        "print(\"%d points\" % len(mesh_points))\n",
        "print(\"%d edges\" % len(mesh_edges))\n",
        "print(\"%d tetrahedra\" % len(mesh_elements))\n",
        "print(\"%d exterior faces\" % len(mesh_faces))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8r1tR8Gqv7N2"
      },
      "source": [
        "# **Import Geo Data**\n",
        "_______________\n",
        "3 types of input data: rock unit, geologic contacts, and orientations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1-v5E1OHHp3"
      },
      "outputs": [],
      "source": [
        "#import from google drive\n",
        "df_rock_unit = pd.read_csv(file_path + input_rock_unit_filename)\n",
        "df_geologic_contacts = pd.read_csv(file_path + input_geologic_contact_filename)\n",
        "df_orientations = pd.read_csv(file_path + input_orientations_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJs4NxE2HUXV",
        "outputId": "120ee079-45f5-4696-e645-3c5288a0e48c"
      },
      "outputs": [],
      "source": [
        "#Preview input data\n",
        "print(\"ROCK UNIT DATA PREVIEW:\")\n",
        "print(df_rock_unit.head(10))\n",
        "print(\"GEOLOGIC CONTACTS DATA PREVIEW:\")\n",
        "print(df_geologic_contacts.head(10))\n",
        "print(\"ORIENTATIONS DATA PREVIEW:\")\n",
        "print(df_orientations.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9J73wvN9SPS"
      },
      "outputs": [],
      "source": [
        "#Accepts Pandas dataframe and filters based on max ans min x,y,z\n",
        "def FilterInputData(df):\n",
        "  return df[\n",
        "    (df[input_name_x].between(min_extents[0], max_extents[0])) &\n",
        "    (df[input_name_y].between(min_extents[1], max_extents[1])) &\n",
        "    (df[input_name_z].between(min_extents[2], max_extents[2]))\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcHFQ9zrLPVu",
        "outputId": "246b78bb-ecde-4ef5-904b-2394713c69b1"
      },
      "outputs": [],
      "source": [
        "# reduce imported data based on the specified extents\n",
        "df_rock_unit = FilterInputData(df_rock_unit)\n",
        "print(\"%d input rock unit data points within specified limits\" % len(df_rock_unit))\n",
        "df_geologic_contacts = FilterInputData(df_geologic_contacts)\n",
        "print(\"%d input geologic contact measurements within specified limits\" % len(df_geologic_contacts))\n",
        "df_orientations = FilterInputData(df_orientations)\n",
        "print(\"%d input orientation measurements within specified limits\" % len(df_orientations))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tfuow-pTeOyg"
      },
      "source": [
        "# **Visualize Drillhole Data with Mesh**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kamUx429pWA5"
      },
      "outputs": [],
      "source": [
        "#plot interactively with an optional mesh slice\n",
        "def interactive_visualize(rock_unit_data, geologic_contact_data=None, orientation_data=None, mesh_points=None, mesh_edges=None, predicted_labels=None):\n",
        "\n",
        "  #Plot rock unit data\n",
        "  fig = px.scatter_3d(rock_unit_data, x=input_name_x, y=input_name_y, z=input_name_z, color=input_name_rock_unit)\n",
        "\n",
        "  #Plot geologic contact data\n",
        "  if geologic_contact_data is not None:\n",
        "    geologic_contact_trace = px.scatter_3d(geologic_contact_data, x=input_name_x, y=input_name_y, z=input_name_z, color=input_name_geologic_contact).data[0]\n",
        "    geologic_contact_trace.marker.symbol = 'x'  # Change marker symbol to 'x'\n",
        "    geologic_contact_trace.marker.size = 4\n",
        "    fig.add_trace(geologic_contact_trace)\n",
        "\n",
        "  #Plot orientation measurement data\n",
        "  if orientation_data is not None:\n",
        "    orientation_trace = px.scatter_3d(orientation_data, x=input_name_x, y=input_name_y, z=input_name_z).data[0]\n",
        "    orientation_trace.marker.symbol = 'diamond-open'\n",
        "    orientation_trace.marker.size = 4\n",
        "    fig.add_trace(orientation_trace)\n",
        "\n",
        "  #Plot mesh points in viewing slice\n",
        "  if mesh_points is not None:\n",
        "    if predicted_labels==None:\n",
        "      predicted_labels = np.zeros(len(mesh_points))\n",
        "    # Creating a DataFrame from the mesh points\n",
        "    df_mesh = pd.DataFrame({\n",
        "        'x': mesh_points[:, 0],\n",
        "        'y': mesh_points[:, 1],\n",
        "        'z': mesh_points[:, 2],\n",
        "        input_name_rock_unit: predicted_labels\n",
        "    })\n",
        "\n",
        "    # Filter points to a slice in y-z plane\n",
        "    mesh_slice = df_mesh[(df_mesh['x'] >= min_viewing_x) & (df_mesh['x'] <= max_viewing_x)]\n",
        "\n",
        "    # Adding new points to the existing figure\n",
        "    fig.add_trace(\n",
        "        px.scatter_3d(mesh_slice, x='x', y='y', z='z', color=input_name_rock_unit).data[0]\n",
        "    )\n",
        "    fig.update_traces(marker=dict(size=5))  # Change the marker size here\n",
        "    fig.update_layout(title='Interactive 3D Plot')\n",
        "\n",
        "  #plot mesh edges in viewing slice\n",
        "  if mesh_points is not None and mesh_edges is not None:\n",
        "    for edge in mesh_edges:\n",
        "          for point in edge:\n",
        "              add_point = True\n",
        "              point_coords = mesh_points[point]\n",
        "              if (point_coords[0] < min_viewing_x or point_coords[0] > max_viewing_x):\n",
        "                  add_point = False\n",
        "                  break\n",
        "          if add_point:\n",
        "              point1, point2 = edge\n",
        "              point1 = mesh_points[point1]\n",
        "              point2 = mesh_points[point2]\n",
        "              x_vals = [point1[0],point2[0]]\n",
        "              y_vals = [point1[1],point2[1]]\n",
        "              z_vals = [point1[2],point2[2]]\n",
        "\n",
        "              fig.add_trace(go.Scatter3d(\n",
        "                  x=x_vals, y=y_vals, z=z_vals,\n",
        "                  mode='lines',\n",
        "                  line=dict(color='grey', width=2),\n",
        "                  name=''\n",
        "              ))\n",
        "\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "q_86jFCGA79T",
        "outputId": "a312943f-faf6-405d-d2cf-302a61d64dab"
      },
      "outputs": [],
      "source": [
        "#visualize input data\n",
        "interactive_visualize(rock_unit_data=df_rock_unit, geologic_contact_data=df_geologic_contacts, orientation_data=df_orientations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VN2wYrNFmC5j"
      },
      "outputs": [],
      "source": [
        "#visualize slice of the initial mesh before adjusting for input data\n",
        "#interactive_visualize(filtered_data, mesh_points, mesh_edges)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VUS6-9gqgfg"
      },
      "source": [
        "# Setup Torch Geometric Dataset Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVpB7bBgFoYr"
      },
      "outputs": [],
      "source": [
        "def euclidean_dist_sq(x1,y1,z1,x2,y2,z2):\n",
        "  return ((x2-x1)*(x2-x1)+(y2-y1)*(y2-y1)+(z2-z1)*(z2-z1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8ccDXjvRfsN"
      },
      "outputs": [],
      "source": [
        "#Method adjusts the mesh such that the closest mesh node to every input data location is adjusted to coincide with the input data location\n",
        "#Method also assigns training data and validation data using masks\n",
        "def AdjustAndLabelMesh(tree, mesh_points, input_data_locations, input_labels, labels, test_mask, train_mask):\n",
        "\n",
        "    if mValidationPercent > 0:\n",
        "        skip_train = round((mTrainingPercent + mValidationPercent) / mValidationPercent)  #assign every nth node to validation dataset instead of train dataset\n",
        "    else:\n",
        "        skip_train = sys.maxsize\n",
        "\n",
        "    labelled_nodes = np.zeros(len(mesh_points))\n",
        "\n",
        "    labelled_count = 0\n",
        "    skipped_count = 0\n",
        "    mean_adjust_dist = 0\n",
        "\n",
        "    for data_point,data_label in zip(input_data_locations, input_labels):\n",
        "        min_dist, min_index = tree.query(data_point, k=1)  # Find the nearest neighbor index and distance\n",
        "\n",
        "        if labelled_nodes[min_index] == 0:\n",
        "            # Update the original mesh_points array at min_index\n",
        "            mesh_points[min_index] = [data_point[0], data_point[1], data_point[2]]\n",
        "            labels[min_index] = data_label #assign class as label\n",
        "            labelled_nodes[min_index] = 1\n",
        "            labelled_count += 1\n",
        "            #update train and test masks\n",
        "            if labelled_count % skip_train == 0:\n",
        "                test_mask[min_index] = True\n",
        "            else:\n",
        "                train_mask[min_index] = True\n",
        "            mean_adjust_dist += min_dist\n",
        "        else:\n",
        "            skipped_count += 1\n",
        "\n",
        "    mean_adjust_dist /= labelled_count\n",
        "\n",
        "    print(\"Total number of nodes labelled: {0}\".format(labelled_count))\n",
        "\n",
        "    print(\"Total number of input points skipped: {0}\".format(skipped_count))\n",
        "    #temporary until meshing is updated to honor all input data points during creation\n",
        "\n",
        "    print(\"Mean mesh adjustment: {:.2f}\".format(mean_adjust_dist))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQXUGNZjMh2r",
        "outputId": "553a51ce-e792-48b1-814d-0c0810123f7a"
      },
      "outputs": [],
      "source": [
        "#Adjust mesh and assign graph labels and masks\n",
        "\n",
        "# Build a KD-tree from mesh_points_np\n",
        "tree = cKDTree(mesh_points)\n",
        "\n",
        "#ROCK UNIT\n",
        "# Input data - convert to np arrays\n",
        "locations_rock_unit_input = df_rock_unit[[input_name_x,input_name_y,input_name_z]].values\n",
        "labels_rock_unit_input = df_rock_unit[input_name_rock_unit].values\n",
        "#Graph labels and masks\n",
        "labels_rock_unit = np.ones(len(mesh_points))*-1\n",
        "train_mask_rock_unit = np.zeros(len(mesh_points), dtype=bool)\n",
        "test_mask_rock_unit = np.zeros(len(mesh_points), dtype=bool)\n",
        "\n",
        "print(\"\")\n",
        "print(\"Mesh adjustment for rock unit measurements:\")\n",
        "\n",
        "AdjustAndLabelMesh(tree,mesh_points,locations_rock_unit_input,labels_rock_unit_input,\n",
        "        labels_rock_unit,test_mask_rock_unit,train_mask_rock_unit)\n",
        "\n",
        "#SCALAR FIELD\n",
        "# Input data - convert to np arrays\n",
        "locations_scalar_field_input = df_geologic_contacts[[input_name_x,input_name_y,input_name_z]].values\n",
        "labels_scalar_field_input = df_geologic_contacts[input_name_geologic_contact].values\n",
        "\n",
        "#Scale scalar field labels [-1,1]\n",
        "#labels_scalar_field_input_scaled = labels_scalar_field_input #initialize in case null\n",
        "if len(labels_scalar_field_input) > 0:\n",
        "        max_scalar_field = np.max(labels_scalar_field_input)\n",
        "        min_scalar_field = np.min(labels_scalar_field_input)\n",
        "        center_scalar_field = (max_scalar_field + min_scalar_field)/2\n",
        "        labels_scalar_field_input_scaled = (labels_scalar_field_input - center_scalar_field) / (max_scalar_field - min_scalar_field) * 2\n",
        "\n",
        "#Graph labels and masks\n",
        "labels_scalar_field = np.ones(len(mesh_points))*-99\n",
        "train_mask_scalar_field = np.zeros(len(mesh_points), dtype=bool)\n",
        "test_mask_scalar_field = np.zeros(len(mesh_points), dtype=bool)\n",
        "\n",
        "if len(labels_scalar_field_input) > 0:\n",
        "        print(\"\")\n",
        "        print(\"Mesh adjustment for scalar field measurements:\")\n",
        "\n",
        "        AdjustAndLabelMesh(tree,mesh_points,locations_scalar_field_input,labels_scalar_field_input_scaled,\n",
        "                labels_scalar_field,test_mask_scalar_field,train_mask_scalar_field)\n",
        "\n",
        "#ORIENTATIONS\n",
        "# Input data - convert to np arrays\n",
        "locations_orientations_input = df_orientations[[input_name_x,input_name_y,input_name_z]].values\n",
        "labels_orientations_input = df_orientations[[input_name_x_vec,input_name_y_vec,input_name_z_vec]].values\n",
        "#Graph labels and masks\n",
        "labels_orientations = np.ones((len(mesh_points),3))*-1\n",
        "train_mask_orientations = np.zeros(len(mesh_points), dtype=bool)\n",
        "test_mask_orientations = np.zeros(len(mesh_points), dtype=bool)\n",
        "\n",
        "if len(labels_orientations_input) > 0:\n",
        "        print(\"\")\n",
        "        print(\"Mesh adjustment for orientation measurements:\")\n",
        "\n",
        "        AdjustAndLabelMesh(tree,mesh_points,locations_orientations_input,labels_orientations_input,\n",
        "                labels_orientations,test_mask_orientations,train_mask_orientations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "un8TnK2qlJas",
        "outputId": "a500a91c-8ceb-49ad-8ab8-6cc998ec8d1d"
      },
      "outputs": [],
      "source": [
        "#visualize the drillhole data and mesh after mesh adjustment\n",
        "interactive_visualize(rock_unit_data=df_rock_unit, geologic_contact_data=df_geologic_contacts, orientation_data=df_orientations,mesh_points=mesh_points)#,mesh_edges=mesh_edges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_2UPD9i5WW5"
      },
      "outputs": [],
      "source": [
        "#populate model vectors\n",
        "node_features_ts = torch.tensor(mesh_points, dtype = torch.float)\n",
        "edge_ts = torch.tensor(mesh_edges, dtype=torch.long).t().contiguous()\n",
        "#Rock Unit\n",
        "labels_rock_unit_ts = torch.tensor(labels_rock_unit, dtype = torch.long)\n",
        "train_mask_rock_unit_ts = torch.tensor(train_mask_rock_unit, dtype = torch.bool)\n",
        "test_mask_rock_unit_ts = torch.tensor(test_mask_rock_unit, dtype = torch.bool)\n",
        "#Scalar Field\n",
        "labels_scalar_field_ts = torch.tensor(labels_scalar_field, dtype = torch.float)\n",
        "train_mask_scalar_field_ts = torch.tensor(train_mask_scalar_field, dtype = torch.bool)\n",
        "test_mask_scalar_field_ts = torch.tensor(test_mask_scalar_field, dtype = torch.bool)\n",
        "#Orientations\n",
        "labels_orientations_ts = torch.tensor(labels_orientations)\n",
        "train_mask_orientations_ts = torch.tensor(train_mask_orientations, dtype = torch.bool)\n",
        "test_mask_orientations_ts = torch.tensor(test_mask_orientations, dtype = torch.bool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HW8hWZlHCOXO"
      },
      "outputs": [],
      "source": [
        "#scale features x,y,z\n",
        "max_extents = np.array(max_extents)\n",
        "min_extents = np.array(min_extents)\n",
        "major_extents = np.max(max_extents - min_extents)\n",
        "center = torch.tensor((max_extents + min_extents)/2)\n",
        "node_features_ts = ((node_features_ts - center) / major_extents / 2).to(torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7w8Y7QuoZFoc"
      },
      "outputs": [],
      "source": [
        "# Print statistics about the graph.\n",
        "def GraphSummaryStats(data):\n",
        "    print(data)\n",
        "    print('==============================================================')\n",
        "\n",
        "    print(f'Number of nodes: {data.num_nodes}')\n",
        "    print(f'Number of edges: {data.num_edges}')\n",
        "    print(f'Average node degree: {(2*data.num_edges) / data.num_nodes:.2f}')\n",
        "    print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "    print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.4f}')\n",
        "    print(f'Number of validation nodes: {data.val_mask.sum()}')\n",
        "    print(f'Contains isolated nodes: {data.has_isolated_nodes()}')\n",
        "    print(f'Contains self-loops: {data.has_self_loops()}')\n",
        "    print(f'Is undirected: {data.is_undirected()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHOz3vR7tVcg",
        "outputId": "4ed71a30-7d5d-41b8-d29b-4b26958a2052"
      },
      "outputs": [],
      "source": [
        "#create torch graph datasets - scalar field\n",
        "data_scalar_field = Data(x=node_features_ts, edge_index=edge_ts, y=labels_scalar_field_ts)\n",
        "data_scalar_field.train_mask = train_mask_scalar_field_ts\n",
        "data_scalar_field.val_mask = test_mask_scalar_field_ts\n",
        "GraphSummaryStats(data_scalar_field)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a26Rr3s8dEBw",
        "outputId": "84e714bc-78b2-4539-83d3-4af0eab3ae3c"
      },
      "outputs": [],
      "source": [
        "#create torch graph datasets - rock unit\n",
        "data_rock_unit = Data(x=node_features_ts, edge_index=edge_ts, y=labels_rock_unit_ts) \n",
        "data_rock_unit.train_mask = train_mask_rock_unit_ts\n",
        "data_rock_unit.val_mask = test_mask_rock_unit_ts\n",
        "GraphSummaryStats(data_rock_unit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#create torch graph datasets - orientations\n",
        "data_orientations = Data(x=node_features_ts, edge_index=edge_ts, y=labels_orientations_ts) \n",
        "data_orientations.train_mask = train_mask_orientations_ts\n",
        "data_orientations.val_mask = test_mask_orientations_ts\n",
        "GraphSummaryStats(data_orientations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Q2k2YksZveJ"
      },
      "outputs": [],
      "source": [
        "#save model input data\n",
        "if save_model_input_data:\n",
        "  torch.save(data_rock_unit, file_path + 'AML/Intermediate_Data/data_rock_unit.dat')\n",
        "  torch.save(data_scalar_field, file_path + 'AML/Intermediate_Data/data_scalar_field.dat')\n",
        "  torch.save(data_orientations, file_path + 'AML/Intermediate_Data/data_orientations.dat')\n",
        "\n",
        "  # Also save the mesh points to a file for subsequent post processing\n",
        "  np.save('AML/Intermediate_Data/mesh_points.npy', mesh_points)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
